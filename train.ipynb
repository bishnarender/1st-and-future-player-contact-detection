{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01fe039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:16:44.311201Z",
     "iopub.status.busy": "2023-04-02T15:16:44.310256Z",
     "iopub.status.idle": "2023-04-02T15:17:18.700399Z",
     "shell.execute_reply": "2023-04-02T15:17:18.699247Z",
     "shell.execute_reply.started": "2023-04-02T15:16:44.311153Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install -q -U openmim\n",
    "# !mim install -q mmcv-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cf4786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:18.703052Z",
     "iopub.status.busy": "2023-04-02T15:17:18.702559Z",
     "iopub.status.idle": "2023-04-02T15:17:18.710215Z",
     "shell.execute_reply": "2023-04-02T15:17:18.708755Z",
     "shell.execute_reply.started": "2023-04-02T15:17:18.702993Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sys \n",
    "# sys.path = [ '../input/dk-1st-data-2/kaggle_data_models', \n",
    "#             '../input/dk-1st-data-3/configs'] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f264757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:18.712930Z",
     "iopub.status.busy": "2023-04-02T15:17:18.712402Z",
     "iopub.status.idle": "2023-04-02T15:17:35.540887Z",
     "shell.execute_reply": "2023-04-02T15:17:35.539006Z",
     "shell.execute_reply.started": "2023-04-02T15:17:18.712868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n",
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os, gc, cv2, sys, random, argparse, importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from shutil import copyfile\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "# https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\n",
    "#from torchcontrib.optim import SWA\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef, f1_score\n",
    "from resnet3d_csn import ResNet3dCSN\n",
    "\n",
    "#import warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from albumentations import ReplayCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174cdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5820caea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.544540Z",
     "iopub.status.busy": "2023-04-02T15:17:35.543857Z",
     "iopub.status.idle": "2023-04-02T15:17:35.549996Z",
     "shell.execute_reply": "2023-04-02T15:17:35.548773Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.544496Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install -q torchview\n",
    "# !pip3 install -q -U graphviz\n",
    "# import graphviz\n",
    "# from torchview import draw_graph\n",
    "# graphviz.set_jupyter_format('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d091d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.551470Z",
     "iopub.status.busy": "2023-04-02T15:17:35.551152Z",
     "iopub.status.idle": "2023-04-02T15:17:35.568487Z",
     "shell.execute_reply": "2023-04-02T15:17:35.567185Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.551440Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"PyTorch\")\n",
    "\n",
    "# base directory \"config\" inside which file \"config_1.py\" is present.\n",
    "# parser.add_argument(\"-C\", \"--config\", default='config_2', type=str, help=\"config filename\") # for kaggle.\n",
    "parser.add_argument(\"-C\", \"--config\", default='configs.config_2', type=str, help=\"config filename\")\n",
    "    # config_1.py file for player-to-ground and config_2.py file for player-to-player.\n",
    "\n",
    "\n",
    "parser.add_argument(\"-M\", \"--mode\", default='train', type=str, help=\"mode type\")\n",
    "parser.add_argument(\"-T\", \"--tta\", default=0, help=\"is use tta for inference\")\n",
    "\n",
    "parser_args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b15fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3671d624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.570207Z",
     "iopub.status.busy": "2023-04-02T15:17:35.569896Z",
     "iopub.status.idle": "2023-04-02T15:17:35.598180Z",
     "shell.execute_reply": "2023-04-02T15:17:35.597056Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.570177Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = importlib.import_module(parser_args.config).cfg\n",
    "# NModel = importlib.import_module(cfg.model).NModel\n",
    "# NDataset = importlib.import_module(cfg.dataset).NDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523ade8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5603963b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.599481Z",
     "iopub.status.busy": "2023-04-02T15:17:35.599119Z",
     "iopub.status.idle": "2023-04-02T15:17:35.605516Z",
     "shell.execute_reply": "2023-04-02T15:17:35.604644Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.599445Z"
    }
   },
   "outputs": [],
   "source": [
    "## for kaggle notebook =>\n",
    "# cfg.out_dir = './'\n",
    "# cfg.train_csv_path = '../input/dk-1st-data-3/slicing_not_g.csv'\n",
    "# cfg.data = '../input/dk-1st-data/kaggle_data/trk_pos.npy'\n",
    "# cfg.path = '../input/dk-1st-data-3/'\n",
    "\n",
    "cfg.out_dir = './models'\n",
    "cfg.train_csv_path = 'slicing_not_g.csv' \n",
    "    # slicing_g.csv for 11_G, slicing_g_next.csv for 15_G, slicing_not_g.csv for 15_all\n",
    "    \n",
    "cfg.data = 'kaggle_data/trk_pos.npy'\n",
    "cfg.path = './'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ab72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377a815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf04ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244608f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.608127Z",
     "iopub.status.busy": "2023-04-02T15:17:35.607628Z",
     "iopub.status.idle": "2023-04-02T15:17:35.661318Z",
     "shell.execute_reply": "2023-04-02T15:17:35.659937Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.608070Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleClassSampler(Sampler):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg=cfg\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.index_class1 = self.df[self.df.contact==1].index.to_list()\n",
    "        self.index_class0 = self.df[self.df.contact==0].index.to_list()\n",
    "        \n",
    "        self.length = int(self.cfg.pos_frac*(len(self.index_class1))) + int(self.cfg.frac*(len(self.index_class0)))\n",
    "\n",
    "    def __iter__(self):\n",
    "        random_choice1 = np.random.choice(self.index_class1, int(self.cfg.pos_frac*(len(self.index_class1))), replace=False)\n",
    "\n",
    "        random_choice0 = np.random.choice(self.index_class0, int(self.cfg.frac*(len(self.index_class0))), replace=False)\n",
    "\n",
    "        print('======',len(random_choice0), len(random_choice1))\n",
    "        # print('======',random_choice0[:10], random_choice1[:10])\n",
    "        \n",
    "        all_indexs = list(random_choice0) + list(random_choice1)\n",
    "\n",
    "        l = np.array(all_indexs)\n",
    "        l = l.reshape(-1)\n",
    "        random.shuffle(l)\n",
    "        return iter(l)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.length)\n",
    "\n",
    "class NDataset(Dataset):\n",
    "    def __init__(self, cfg, df, tfms=None, fold_id = 0, is_train = True):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)#.sample(frac = 1.0, random_state=42) \n",
    "        self.cfg = cfg\n",
    "        self.fold_id = fold_id\n",
    "        self.transform = tfms\n",
    "        self.is_train = is_train\n",
    "        self.feat_cols = ['x_position_1', 'y_position_1', 'distance']\n",
    "        self.trk_step = 0\n",
    "        if self.is_train:\n",
    "            self.e_transform = self.cfg.train_e_transform\n",
    "            self.s_transform = self.cfg.train_s_transform\n",
    "        else:\n",
    "            self.e_transform = self.cfg.val_e_transform\n",
    "            self.s_transform = self.cfg.val_s_transform\n",
    "            \n",
    "        self.trk_pos = np.load(cfg.data, allow_pickle=True).item()\n",
    "\n",
    "        print(f'Fold: {fold_id}, is_train: {is_train}, total frame {len(self.df)}')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index]\n",
    "            # row => \n",
    "            # path        slicing_g/58188_001358_46171_G_0591_50\n",
    "            # fold                                             2\n",
    "            # contact                                          0\n",
    "            # distance                                  0.274579\n",
    "            # step                                            50\n",
    "            # e_empty                                          0\n",
    "            # s_empty                                          0\n",
    "            # Name: 0, dtype: object        \n",
    "\n",
    "        path = row['path']\n",
    "        step = row['step']\n",
    "        idx = path.split('/')[-1]\n",
    "        vid = '_'.join(idx.split('_')[:2])\n",
    "\n",
    "        if '_ext' in path:\n",
    "            idx1 = idx.split('_')[2]\n",
    "        else:\n",
    "            idx1 = int(idx.split('_')[2])\n",
    "            \n",
    "        if not self.cfg.is_G:\n",
    "            if '_ext' in path:\n",
    "                idx2 = idx.split('_')[3]\n",
    "            else:\n",
    "                idx2 = int(idx.split('_')[3])\n",
    "        \n",
    "        path = cfg.path + path\n",
    "        e_path = f'{path}_e.npy'\n",
    "        s_path = f'{path}_s.npy'\n",
    "\n",
    "        e_images = np.load(e_path)\n",
    "        s_images = np.load(s_path)\n",
    "\n",
    "        if self.cfg.skip_frame > 0:\n",
    "            e_images = e_images[self.cfg.skip_frame:-self.cfg.skip_frame,:,:,:]\n",
    "            s_images = s_images[self.cfg.skip_frame:-self.cfg.skip_frame,:,:,:]\n",
    "\n",
    "        num_empty = 0\n",
    "        for img in e_images:\n",
    "            h, w, c = img.shape \n",
    "                # img.shape, np.sum(img<2), h*w*c => (256, 256, 3), 18, 196608\n",
    "                # 18 / 196608 => 0.00009\n",
    "            if np.sum(img<2)/(h*w*c) > 0.9:\n",
    "                num_empty += 1\n",
    "                \n",
    "            # len(e_images), num_empty => 23, 0        \n",
    "        if len(e_images) - num_empty < 2:\n",
    "            # print('e empty')\n",
    "            e_images = s_images.copy()\n",
    "\n",
    "        num_empty = 0\n",
    "        for img in s_images:\n",
    "            h, w, c = img.shape \n",
    "            if np.sum(img<2)/(h*w*c) > 0.9:\n",
    "                num_empty += 1\n",
    "                \n",
    "        if len(s_images) - num_empty < 2:\n",
    "            # print('s empty')\n",
    "            s_images = e_images.copy()\n",
    "\n",
    "        if self.trk_step == 0:\n",
    "            self.trk_step = len(e_images)//2\n",
    "        \n",
    "        # self.trk_step => 11        \n",
    "        if not self.cfg.is_G:\n",
    "            trk_images = self.render_trk(vid, step, idx1, idx2, self.trk_pos)\n",
    "\n",
    "        replay = None\n",
    "        e_images_ = []\n",
    "        # applying same augmentation to all frames of particular vid.\n",
    "        for img in e_images:\n",
    "            if replay is None:\n",
    "                sample = self.e_transform(image=img)\n",
    "                replay = sample[\"replay\"] # 'replay' key contains the play that played with image.\n",
    "            else:\n",
    "                sample = ReplayCompose.replay(replay, image=img)\n",
    "            img = sample[\"image\"]\n",
    "            e_images_.append(img)\n",
    "        \n",
    "        e_images = None # saving space\n",
    "        \n",
    "        replay = None\n",
    "        s_images_ = []\n",
    "        # applying same augmentation to all frames of particular vid.\n",
    "        for img in s_images:\n",
    "            if replay is None:\n",
    "                sample = self.s_transform(image=img)\n",
    "                replay = sample[\"replay\"]\n",
    "            else:\n",
    "                sample = ReplayCompose.replay(replay, image=img)\n",
    "            img = sample[\"image\"]\n",
    "            s_images_.append(img)\n",
    "\n",
    "        s_images = None # saving space\n",
    "        \n",
    "        #simple trk image augmentation\n",
    "        flip_trk_lr = False\n",
    "        flip_trk_ud = False\n",
    "        is_swap = False\n",
    "        if self.is_train:\n",
    "            if random.random() < 0.5:\n",
    "                flip_trk_lr = True\n",
    "            if random.random() < 0.5:\n",
    "                flip_trk_ud = True\n",
    "            if random.random() < 0.5:\n",
    "                is_swap = True\n",
    "\n",
    "        # s_images_[0].shape => (256, 256, 3)\n",
    "        images = []\n",
    "        for i in range(len(s_images_)):\n",
    "            if not self.cfg.is_G:\n",
    "                trk_img = trk_images[i]\n",
    "                if flip_trk_lr:\n",
    "                    trk_img = np.fliplr(trk_img)\n",
    "                    # reverse the order of elements along axis 1 (left/right).\n",
    "                if flip_trk_ud:\n",
    "                    trk_img = np.flipud(trk_img)\n",
    "                    # Reverse the order of elements along axis 0 (up/down).\n",
    "                    \n",
    "                # s_img = np.vstack([trk_img, s_images_[i]])\n",
    "                if is_swap:\n",
    "                    img = np.hstack([s_images_[i], trk_img, e_images_[i]])\n",
    "                else:\n",
    "                    img = np.hstack([e_images_[i], trk_img, s_images_[i]])\n",
    "            else:\n",
    "                if is_swap:\n",
    "                    img = np.hstack([s_images_[i], e_images_[i]])\n",
    "                else:\n",
    "                    img = np.hstack([e_images_[i], s_images_[i]])\n",
    "\n",
    "            images.append(img)\n",
    "        \n",
    "        \n",
    "        e_images_ = s_images_ = None # saving space\n",
    "        \n",
    "        # images[0].shape => (256, 512, 3)            \n",
    "        img = np.array(images)\n",
    "        # img.shape => (23, 256, 512, 3)  \n",
    "        \n",
    "        images = None # saving space\n",
    "            \n",
    "        if self.cfg.model in ['model_25d']:\n",
    "            # img = img.transpose(0,3,1,2)\n",
    "            img = np.concatenate(img, axis=2)\n",
    "            img = img.transpose(2,0,1)\n",
    "        else:\n",
    "            img = img.transpose(3,0,1,2) #C T H W\n",
    "            \n",
    "        \n",
    "        # img.shape => (3,23,256,512)\n",
    "        img = img/255.\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "\n",
    "        target = row['contact']\n",
    "\n",
    "        if self.cfg.use_meta:\n",
    "            feat = row[self.feat_cols]\n",
    "        else:\n",
    "            feat = target\n",
    "\n",
    "        if self.cfg.use_oof and self.is_train:\n",
    "            feat = row['pred']\n",
    "\n",
    "        # print(img.shape, mask.shape)\n",
    "\n",
    "        return torch.tensor(img, dtype=torch.float), torch.tensor(target, dtype=torch.float), torch.tensor(feat, dtype=torch.float)\n",
    "\n",
    "    def render_trk(self, vid, step, idx1, idx2, trk_pos):\n",
    "        '''\n",
    "        append image - showing players head position for both video at particular step. both video => end and side view.\n",
    "        'away' team players' head position is appended in the 3rd channel of image.\n",
    "        'home' team players' head position is appended in the 2nd channel of image.\n",
    "        both team players' head position is appended in the 1st channel of image.\n",
    "        '''\n",
    "\n",
    "        if self.is_train:\n",
    "            shift_x = random.randint(-10,10)\n",
    "            # random.randint(a,b) => Return a random integer N such that a <= N <= b.\n",
    "            # shift_x => 8\n",
    "            shift_y = random.randint(-20,20)\n",
    "            # shift_y => -4            \n",
    "        else:\n",
    "            shift_x = 0\n",
    "            shift_y = 0\n",
    "\n",
    "        # d_x = 0.1*random.randint(30,60)\n",
    "        d_x = 5\n",
    "        scale = 60/d_x # scale to fit players in image size (256,128).\n",
    "        \n",
    "        idx = f'{vid}_{step}'\n",
    "        images = []\n",
    "        x1 = trk_pos[idx][idx1]['x']#idx1 => player_id_1\n",
    "        y1 = trk_pos[idx][idx1]['y']\n",
    "\n",
    "        x2 = trk_pos[idx][idx2]['x']#idx2 => player_id_2\n",
    "        y2 = trk_pos[idx][idx2]['y']\n",
    "        \n",
    "        # x1,y1,x2,y2 => 40.33, 25.28, 40.11, 26.73        \n",
    "        xc = 0.5*x1 + 0.5*x2\n",
    "        yc = 0.5*y1 + 0.5*y2\n",
    "        # xc, yc => 40.22 26.005000000000003        \n",
    "        # step, self.trk_step => 0, 9 (9 when data is not_ground)\n",
    "        for st in range(step-self.trk_step, step+self.trk_step + 1):\n",
    "            this_idx = f'{vid}_{st}'\n",
    "            img = np.ones((3, self.cfg.img_size, 128), dtype=np.uint8)\n",
    "            # img.shape => (3, 256, 128)\n",
    "            if this_idx in trk_pos:\n",
    "                for p_id, meta in trk_pos[this_idx].items():\n",
    "                    x = meta['x']\n",
    "                    y = meta['y']\n",
    "                    t = meta['t']\n",
    "                    # x,y,t,d_x => 52.83, 26.05, away, 5                    \n",
    "                    x = x - xc + d_x # d_x; as length of x-axis is 128\n",
    "                    y = y - yc + (2*d_x) # 2*d_x; as length of y-axis is 256\n",
    "                    # x,y,scale => 17.61, 10.044999999999998, 12.0\n",
    "                    \n",
    "                    # shift_x and shift_y; every time to show different proportional length b/w players.\n",
    "                    x = round(x*scale) + shift_x\n",
    "                    y = round(y*scale) + shift_y\n",
    "                    # x,y => 204, 119\n",
    "\n",
    "                    if x>0 and y>0 and x<128 and y<self.cfg.img_size:\n",
    "                        if self.cfg.trk_type == 1:\n",
    "                            #v1\n",
    "                            radius = 3\n",
    "                            val = 125# other players pixel value\n",
    "                            if p_id in [idx1, idx2]:# p_id => player_id\n",
    "                                radius = 5\n",
    "                                val = 255# focus player pixel value\n",
    "\n",
    "                            cv2.circle(img[0], (x, y), radius, val, thickness=-1)\n",
    "                            if t == 'home':\n",
    "                                cv2.circle(img[1], (x, y), radius, val, thickness=-1)\n",
    "                            else:\n",
    "                                cv2.circle(img[2], (x, y), radius, val, thickness=-1)\n",
    "\n",
    "                        elif self.cfg.trk_type == 2:\n",
    "                            ##v2\n",
    "                            radius = 4\n",
    "                            val = 255\n",
    "                            if p_id in [idx1, idx2]:\n",
    "                                radius = 6\n",
    "                                val = 255\n",
    "\n",
    "                            # if p_id in [idx1, idx2]:\n",
    "                            #     cv2.circle(img[0], (x, y), radius, val, thickness=-1)\n",
    "                            if t == 'home':\n",
    "                                cv2.circle(img[1], (x, y), radius, val, thickness=-1)\n",
    "                            else:\n",
    "                                cv2.circle(img[2], (x, y), radius, val, thickness=-1)\n",
    "\n",
    "            img = img.transpose(1,2,0)\n",
    "            images.append(img)\n",
    "\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be908a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:19:23.479296Z",
     "iopub.status.busy": "2023-04-02T15:19:23.478825Z",
     "iopub.status.idle": "2023-04-02T15:19:24.769880Z",
     "shell.execute_reply": "2023-04-02T15:19:24.767667Z",
     "shell.execute_reply.started": "2023-04-02T15:19:23.479241Z"
    }
   },
   "outputs": [],
   "source": [
    "# for debugging\n",
    "# c = NDataset(cfg, a, tfms=b, fold_id = 0, is_train=True)\n",
    "# k = c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db68038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:19:27.469585Z",
     "iopub.status.busy": "2023-04-02T15:19:27.469028Z",
     "iopub.status.idle": "2023-04-02T15:19:27.694659Z",
     "shell.execute_reply": "2023-04-02T15:19:27.693101Z",
     "shell.execute_reply.started": "2023-04-02T15:19:27.469529Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8b8777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.701118Z",
     "iopub.status.busy": "2023-04-02T15:17:35.700774Z",
     "iopub.status.idle": "2023-04-02T15:17:35.712525Z",
     "shell.execute_reply": "2023-04-02T15:17:35.711190Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.701076Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd7f277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.714356Z",
     "iopub.status.busy": "2023-04-02T15:17:35.713950Z",
     "iopub.status.idle": "2023-04-02T15:17:35.723753Z",
     "shell.execute_reply": "2023-04-02T15:17:35.722522Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.714317Z"
    }
   },
   "outputs": [],
   "source": [
    "# # plotter Cid = 7\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "# fx, arr = plt.subplots(1,1)\n",
    "# arr.imshow(np.fliplr(k[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3a842b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.726217Z",
     "iopub.status.busy": "2023-04-02T15:17:35.725788Z",
     "iopub.status.idle": "2023-04-02T15:17:35.738586Z",
     "shell.execute_reply": "2023-04-02T15:17:35.737332Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.726172Z"
    }
   },
   "outputs": [],
   "source": [
    "class NModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.backbone = ResNet3dCSN(\n",
    "            pretrained2d=False,\n",
    "            in_channels = 3,\n",
    "            pretrained=None,\n",
    "            depth=int(cfg.model_name[1:-2]),\n",
    "            with_pool2=False,\n",
    "            bottleneck_mode=cfg.model_name[-2:],\n",
    "            norm_eval=False,\n",
    "            zero_init_residual=False)\n",
    "\n",
    "        #self.final = nn.Linear(2048+1024, out_features=1)\n",
    "        self.final = nn.Linear(2048+1024, out_features=1)\n",
    "        if cfg.pool_type == 'avg':\n",
    "            self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1)) #if pool ==\"avg\" else \n",
    "        else:\n",
    "            self.avg_pool = nn.AdaptiveMaxPool3d((1, 1, 1))\n",
    "        self.dropout = nn.Dropout(0.0)# 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "            # x,shape => torch.Size([2, 3, 23, 256, 512])\n",
    "        bs = x.size(0)  \n",
    "            # bs => batch_size\n",
    "            \n",
    "        if x.size(1) == 1:\n",
    "                # x.shape => torch.Size([2, 1, 23, 256, 512])\n",
    "            x = x.repeat(1, 3, 1, 1, 1)[:, :, :, :, :]\n",
    "                # x.shape => torch.Size([2, 3, 23, 256, 512])\n",
    "            \n",
    "        x = self.backbone(x)\n",
    "        # x = x[-1]\n",
    "        # x = self.avg_pool(x)\n",
    "\n",
    "        # type(x) => tuple\n",
    "        # x[-1].shape => torch.Size([2, 2048, 3, 8, 16])\n",
    "        # x[-2].shape => torch.Size([2, 1024, 6, 16, 32])\n",
    "        x_fast = self.avg_pool(x[-2])\n",
    "        # x_fast.shape => torch.Size([2, 1024, 1, 1, 1])\n",
    "        x_slow = self.avg_pool(x[-1])\n",
    "        # x_slow.shape => torch.Size([2, 2048, 1, 1, 1])\n",
    "            \n",
    "        x = torch.cat((x_slow, x_fast), dim=1)\n",
    "            # x.shape => torch.Size([2, 3072, 1, 1, 1])\n",
    "        x = self.dropout(x)\n",
    "        x = x.flatten(start_dim=1)# start_dim => start dimension\n",
    "            # x.shape => torch.Size([2, 3072])\n",
    "\n",
    "        x = self.final(x)# mat1 and mat2 shapes can be multiplied (2x3072 and 3072x1)\n",
    "            # x.shape => torch.Size([2, 1])\n",
    "\n",
    "        return {'out1':x, 'emb':x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858fe482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.741093Z",
     "iopub.status.busy": "2023-04-02T15:17:35.740630Z",
     "iopub.status.idle": "2023-04-02T15:17:35.754630Z",
     "shell.execute_reply": "2023-04-02T15:17:35.753235Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.741042Z"
    }
   },
   "outputs": [],
   "source": [
    "#m = NModel(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07a13ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.756887Z",
     "iopub.status.busy": "2023-04-02T15:17:35.756484Z",
     "iopub.status.idle": "2023-04-02T15:17:35.765528Z",
     "shell.execute_reply": "2023-04-02T15:17:35.764320Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.756851Z"
    }
   },
   "outputs": [],
   "source": [
    "#draw_graph(m, input_data = torch.randn(1, 3, 23, 256, 512), expand_nested=True, save_graph=True, device='cpu').visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd2f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7711c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49799b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d17ae92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.768335Z",
     "iopub.status.busy": "2023-04-02T15:17:35.767254Z",
     "iopub.status.idle": "2023-04-02T15:17:35.782752Z",
     "shell.execute_reply": "2023-04-02T15:17:35.781491Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.768286Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_NO_CUDA_MEMORY_CACHING\"]=\"1\"\n",
    "def seed_everything(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "#     if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    #         torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False        \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1646a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14644ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.785242Z",
     "iopub.status.busy": "2023-04-02T15:17:35.784512Z",
     "iopub.status.idle": "2023-04-02T15:17:35.797286Z",
     "shell.execute_reply": "2023-04-02T15:17:35.795977Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.785201Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"output/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f5f7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.800128Z",
     "iopub.status.busy": "2023-04-02T15:17:35.799004Z",
     "iopub.status.idle": "2023-04-02T15:17:35.810376Z",
     "shell.execute_reply": "2023-04-02T15:17:35.809015Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.800047Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to selectively load \"state_dict keys\" from two state_dict.\n",
    "def intersect_dicts(da, db, exclude=()):\n",
    "    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values\n",
    "    return {k: v for k, v in da.items() if k in db and not any(x in k for x in exclude) and v.shape == db[k].shape}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1277a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.812828Z",
     "iopub.status.busy": "2023-04-02T15:17:35.811692Z",
     "iopub.status.idle": "2023-04-02T15:17:35.823585Z",
     "shell.execute_reply": "2023-04-02T15:17:35.822370Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.812788Z"
    }
   },
   "outputs": [],
   "source": [
    "def logfile(message, lg_path):\n",
    "    print(message)\n",
    "    with open(lg_path, 'a+') as logger:\n",
    "        logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0a8623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.826335Z",
     "iopub.status.busy": "2023-04-02T15:17:35.825522Z",
     "iopub.status.idle": "2023-04-02T15:17:35.836176Z",
     "shell.execute_reply": "2023-04-02T15:17:35.834990Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.826259Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(cfg, model):\n",
    "    params = [{\n",
    "            \"params\": [param for name, param in model.named_parameters()],\n",
    "            \"lr\": cfg.lr,\n",
    "        }]\n",
    "\n",
    "    if cfg.optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(params, lr=params[0][\"lr\"], weight_decay=cfg.weight_decay)\n",
    "    elif cfg.optimizer == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(params, lr=params[0][\"lr\"], momentum=0.9, nesterov=True,weight_decay=cfg.weight_decay)\n",
    "    elif cfg.optimizer == \"AdamW\":\n",
    "        optimizer = torch.optim.AdamW(params, lr=params[0][\"lr\"], weight_decay=cfg.weight_decay)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef17c6f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.838458Z",
     "iopub.status.busy": "2023-04-02T15:17:35.837597Z",
     "iopub.status.idle": "2023-04-02T15:17:35.851250Z",
     "shell.execute_reply": "2023-04-02T15:17:35.850038Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.838419Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scheduler(cfg, optimizer, total_steps=0):\n",
    "    iter_update = False\n",
    "    if cfg.scheduler == \"steplr\":\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40000, gamma=0.8)\n",
    "    elif cfg.scheduler == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs, eta_min=1e-6, verbose=False)\n",
    "    elif cfg.scheduler == \"linear\":\n",
    "        iter_update = True\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=(total_steps // cfg.batch_size),\n",
    "        )\n",
    "        print(\"num_steps\", (total_steps // cfg.batch_size))\n",
    "    elif cfg.scheduler == \"step\":\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 25, 30], gamma=0.5, verbose=False)\n",
    "    elif cfg.scheduler == \"cosinewarmup\":\n",
    "        iter_update = True\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=cfg.warmup,\n",
    "            num_training_steps=(total_steps // cfg.batch_size),\n",
    "        )\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    return scheduler, iter_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5805b5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.854060Z",
     "iopub.status.busy": "2023-04-02T15:17:35.853209Z",
     "iopub.status.idle": "2023-04-02T15:17:35.872547Z",
     "shell.execute_reply": "2023-04-02T15:17:35.871412Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.853965Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(fold_id = 0):\n",
    "    train_transform = cfg.train_transform\n",
    "    val_transform = cfg.val_transform\n",
    "\n",
    "    df = pd.read_csv(cfg.train_csv_path)\n",
    "    print(df.shape)\n",
    "    \n",
    "    if cfg.use_oof:\n",
    "        ffs = []\n",
    "        for ff in [0,1,2,3,4]:\n",
    "            if ff != fold_id:\n",
    "                f_df = pd.read_csv(f'{cfg.pl_path}/oof_f{ff}.csv')\n",
    "                ffs.append(f_df)\n",
    "        train_df = pd.concat(ffs)\n",
    "    else:\n",
    "        # train_df = df[50000:][df.fold!=fold_id]\n",
    "        train_df = df[df.fold!=fold_id]\n",
    "\n",
    "    if not cfg.sampler:\n",
    "        train_df1 = train_df[train_df.contact==1]\n",
    "        train_df0 = train_df[train_df.contact==0]\n",
    "        \n",
    "        # shuffling the both dataframe.\n",
    "        train_df1 = train_df1.sample(frac=1.0)\n",
    "        train_df0 = train_df0.sample(frac=1.0)\n",
    "\n",
    "            # cfg.frac, train_df1.shape[0] => 3, 111\n",
    "        num_neg = int(cfg.frac*train_df1.shape[0])\n",
    "            # num_neg => 333 (3 times the positive samples)\n",
    "            \n",
    "        train_df0 = train_df0.head(num_neg)\n",
    "        train_df = pd.concat([train_df0, train_df1])\n",
    "\n",
    "    # shuffling the dataframe.\n",
    "    train_df = train_df.sample(frac = 1.0) \n",
    "    print(train_df.contact.value_counts())\n",
    "    \n",
    "    # return df, train_transform\n",
    "    train_dataset = NDataset(cfg, train_df, tfms=train_transform, fold_id = fold_id, is_train=True)\n",
    "\n",
    "    if fold_id < 5:\n",
    "        val_df = df[df.fold==fold_id]\n",
    "    else:\n",
    "        val_df = df[df.fold==0]\n",
    "\n",
    "    if cfg.mode not in ['val']:\n",
    "        # val_df = val_df.head(100)\n",
    "        # val_df = val_df.sample(frac=0.1, random_state=42)\n",
    "        val_df1 = val_df[val_df.contact==1]\n",
    "        val_df0 = val_df[val_df.contact==0]\n",
    "        val_df1 = val_df1.sample(frac=0.1*cfg.val_frac, random_state=42)\n",
    "        val_df0 = val_df0.sample(frac=0.04*cfg.val_frac, random_state=42)\n",
    "        val_df = pd.concat([val_df0, val_df1])\n",
    "        val_df = val_df.sample(frac = 1.0, random_state=42) \n",
    "        print(val_df.contact.value_counts())\n",
    "\n",
    "    val_dataset = NDataset(cfg, val_df, tfms=val_transform,  fold_id = fold_id, is_train = False)\n",
    "    \n",
    "    print('cfg.sampler => ', cfg.sampler)\n",
    "    if not cfg.sampler:\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            num_workers=cfg.num_workers,\n",
    "            shuffle=True)\n",
    "    else:\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            sampler=SimpleClassSampler(train_df, cfg),\n",
    "            num_workers=cfg.num_workers,\n",
    "            drop_last=True\n",
    "            )\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        num_workers=cfg.num_workers,\n",
    "        shuffle=False)\n",
    "\n",
    "    total_steps = len(train_dataloader)*cfg.batch_size\n",
    "\n",
    "    # for i, batch in enumerate(train_dataset):\n",
    "    #     img, lb, f = batch\n",
    "    #     print(img.shape)\n",
    "    #     img = img.numpy().transpose(1,2,3,0)*255\n",
    "    #     # out = img[5,:,:,:3]\n",
    "    #     # mask0 = np.uint8(255*mask[0].numpy())\n",
    "    #     # print(mask0.shape)\n",
    "    #     # mask0 = cv2.cvtColor(mask0,cv2.COLOR_GRAY2RGB)\n",
    "    #     # out = np.hstack([img, mask0])\n",
    "    #     for ii in range(img.shape[0]):\n",
    "    #         im = img[ii]\n",
    "    #         cv2.imwrite(f'{cfg.out_dir}/s{i}_{ii}.jpg', im)\n",
    "    #     if i>10:\n",
    "    #         break\n",
    "    # exit()\n",
    "\n",
    "    return train_dataloader, val_dataloader, total_steps, val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b590d274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T15:17:35.874891Z",
     "iopub.status.busy": "2023-04-02T15:17:35.874169Z",
     "iopub.status.idle": "2023-04-02T15:17:35.926129Z",
     "shell.execute_reply": "2023-04-02T15:17:35.925019Z",
     "shell.execute_reply.started": "2023-04-02T15:17:35.874844Z"
    }
   },
   "outputs": [],
   "source": [
    "# a,b = get_dataloader(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1975b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f73256f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_func(model, val_loader, tta=int(parser_args.tta)):\n",
    "    if cfg.loss_fn == 'bce':\n",
    "        loss_cls_fn = nn.BCEWithLogitsLoss()\n",
    "    elif cfg.loss_fn == 'focal':\n",
    "        loss_cls_fn = BCEFocalLoss()\n",
    "    else:\n",
    "        loss_cls_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    count = 1\n",
    "    device = cfg.device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        bar = tqdm(val_loader)\n",
    "        for batch_idx, batch_data in enumerate(bar):\n",
    "            if cfg.debug and batch_idx>10:\n",
    "                break\n",
    "            images, lb, feat = batch_data\n",
    "            images = images.float().to(device)\n",
    "            if cfg.use_meta:\n",
    "                pred = model(images, feat.to(device))\n",
    "                logit = pred['out1']\n",
    "            else:\n",
    "                pred = model(images)\n",
    "                logit = pred['out1']\n",
    "                if tta:\n",
    "                    pred1 = model(images.flip(-1))\n",
    "                    logit = 0.5*logit + 0.5*pred1['out1']\n",
    "\n",
    "            if cfg.loss_fn in ['bce', 'focal']:\n",
    "                loss = loss_cls_fn(logit, lb.to(device).unsqueeze(-1))\n",
    "            else:\n",
    "                loss = loss_cls_fn(logit, lb.to(device).long())\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            smooth_loss = np.mean(losses[:])\n",
    "\n",
    "            bar.set_description(f'loss: {loss.item():.5f}, smth: {smooth_loss:.5f}')\n",
    "\n",
    "            y_trues.append(lb.detach().cpu().numpy())\n",
    "            if cfg.loss_fn in ['bce', 'focal']:\n",
    "                out = logit.sigmoid().detach().cpu().numpy()\n",
    "            else:\n",
    "                out = logit.softmax(-1).detach().cpu().numpy()[:,1]\n",
    "                # print(out.shape)\n",
    "            y_preds.append(out)\n",
    "\n",
    "    y_preds = np.concatenate(y_preds).astype(np.float64)\n",
    "    y_trues = np.concatenate(y_trues).astype(np.float64)\n",
    "    print(y_preds.shape, y_trues.shape)\n",
    "\n",
    "    y_preds = y_preds.reshape(-1)\n",
    "    y_trues = y_trues.reshape(-1)\n",
    "\n",
    "    if cfg.mode == 'test':\n",
    "        acc = 1\n",
    "        auc = 1\n",
    "        macro_score = 1\n",
    "    else:\n",
    "        acc = matthews_corrcoef(y_trues>0.5, y_preds > 0.5)\n",
    "        auc = roc_auc_score(y_trues>0.5, y_preds)\n",
    "        # micro_score = f1_score(y_trues>0.5, y_preds > 0.5, average='micro')\n",
    "        macro_score = f1_score(y_trues>0.5, y_preds > 0.5, average='macro')\n",
    "\n",
    "    val_loss = np.mean(losses)\n",
    "    return val_loss, auc, acc, macro_score, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0f1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e0af1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    random_seed = 42\n",
    "    _ = seed_everything(random_seed)\n",
    "    \n",
    "    f_preds = []\n",
    "    models = []\n",
    "    for fold_id in cfg.folds:\n",
    "        device = cfg.device\n",
    "        model = NModel(cfg)\n",
    "\n",
    "        if cfg.num_freeze > 0 and cfg.mode == 'train':\n",
    "            for cc, (name, params) in enumerate(model.backbone.named_parameters()):\n",
    "                # if cc < cfg.num_freeze or 'layer1.' in name or 'layer2.' in name or 'layer3.' in name:\n",
    "                if cc < cfg.num_freeze or 'layer1.' in name:\n",
    "                # if cc < cfg.num_freeze:\n",
    "                    print(f'layer {cc} {name} is frozen!')\n",
    "                    params.requires_grad = False\n",
    "\n",
    "        model.to(device)        \n",
    "        \n",
    "        if cfg.mode == 'train':\n",
    "            log_path = f'{cfg.out_dir}/log_f{fold_id}.txt'\n",
    "            logfile(f'====== FOLD {fold_id} =======', log_path)\n",
    "\n",
    "            if len(cfg.load_weight) > 10:\n",
    "                if '.pth' in cfg.load_weight:\n",
    "                    load_weight = cfg.load_weight\n",
    "                else:\n",
    "                    load_weight = f'{cfg.load_weight}_last_f{(fold_id)%5}.pth'\n",
    "\n",
    "                logfile(f'load pretrained weight {load_weight}!!!', log_path)\n",
    "                state_dict = torch.load(load_weight, map_location=device)  # load checkpoint\n",
    "                if 'state_dict' in state_dict.keys():\n",
    "                    state_dict = state_dict['state_dict']\n",
    "                state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=[])  # intersect\n",
    "                model.load_state_dict(state_dict, strict=False)  # load\n",
    "                logfile('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), load_weight), log_path)  # report\n",
    "                del state_dict\n",
    "                gc.collect()\n",
    "            \n",
    "            train_loader, valid_loader, total_steps, val_df =  get_dataloader(fold_id)\n",
    "            total_steps = total_steps*cfg.epochs\n",
    "\n",
    "            optimizer = get_optimizer(cfg, model)\n",
    "\n",
    "            if cfg.use_swa:\n",
    "                optimizer = SWA(optimizer, swa_start=500, swa_freq=50, swa_lr=None)\n",
    "\n",
    "            scheduler, iter_update = get_scheduler(cfg, optimizer, total_steps)\n",
    "\n",
    "            best_loss = 1e6\n",
    "            best_auc = best_macro = best_acc = metric = 0\n",
    "            step = 0\n",
    "            l_acc = [5,7,9,11]# values to be assigned to n_accumulate.\n",
    "            for epoch in range(1,cfg.epochs+1):\n",
    "                if not iter_update:\n",
    "                    scheduler.step(epoch)\n",
    "                if cfg.loss_fn == 'bce':\n",
    "                    loss_cls_fn = nn.BCEWithLogitsLoss()\n",
    "                elif cfg.loss_fn == 'focal':\n",
    "                    loss_cls_fn = BCEFocalLoss()\n",
    "                else:\n",
    "                    loss_cls_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "                # enabled (bool, optional):  If ``False``, disables gradient scaling.\n",
    "                scaler = torch.cuda.amp.GradScaler(enabled=cfg.apex)\n",
    "\n",
    "                model.train()\n",
    "                losses = []\n",
    "                bar = tqdm(train_loader)\n",
    "                                \n",
    "                cfg.n_accumulate = l_acc[-1]                \n",
    "                #  np.roll; roll array elements along a given axis.\n",
    "                l_acc = np.roll(l_acc, shift=1)\n",
    "                \n",
    "                k=0                \n",
    "                for batch_idx, batch_data in enumerate(bar):                    \n",
    "                    step +=1\n",
    "                    if cfg.debug and batch_idx>10:\n",
    "                        break\n",
    "                    images, lb, feat = batch_data\n",
    "                    # lb.shape => torch.Size([2])  \n",
    "                    # lb is target or ['contact'].\n",
    "                    \n",
    "                    if cfg.use_meta:\n",
    "                        pred = model(images.float().to(device), feat.to(device))\n",
    "                    else:                        \n",
    "                        pred = model(images.float().to(device))                                                \n",
    "                    logit = pred['out1']\n",
    "                    # print(logit.shape)\n",
    "                    if cfg.loss_fn in ['bce', 'focal']:\n",
    "                        loss = loss_cls_fn(logit, lb.to(device).unsqueeze(-1))\n",
    "                            # lb.to(device).unsqueeze(-1) => torch.Size([2, 1])\n",
    "                    else: \n",
    "                        loss = loss_cls_fn(logit, lb.to(device).long())\n",
    "\n",
    "                    if cfg.use_oof:\n",
    "                        loss1 = loss_cls_fn(logit, feat.to(device).unsqueeze(-1))\n",
    "                        loss = 0.5*loss + 0.5*loss1\n",
    "                    \n",
    "                    scaler.scale(loss/cfg.n_accumulate).backward()\n",
    "                    \n",
    "                    if (k+1)%cfg.n_accumulate == 0:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                        if batch_idx%100 == 0 and batch_idx>300 and cfg.use_swa: optimizer.update_swa()\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        k = -1\n",
    "                    k+=1\n",
    "                    \n",
    "                    if iter_update:\n",
    "                        scheduler.step()\n",
    "\n",
    "                    losses.append(loss.item())\n",
    "                    smooth_loss = np.mean(losses[-2000:])\n",
    "\n",
    "                    bar.set_description(f'loss: {loss.item():.5f}, smth: {smooth_loss:.5f}, LR {scheduler.get_lr()[0]:.6f}')\n",
    "\n",
    "                train_loss = np.mean(losses)\n",
    "\n",
    "                loss_valid, auc, acc, macro_score, y_preds = valid_func(model, valid_loader)\n",
    "                logfile(f'[EPOCH] {epoch}, train_loss: {train_loss:.6f},  val loss: {loss_valid:.6f}, auc: {auc:.5f}, acc {acc:.5f}, macro_score {macro_score:.5f}', log_path)\n",
    "\n",
    "                if metric <= (auc - loss_valid):\n",
    "                    logfile(f'[EPOCH] {epoch} ===============> best_metric ({metric:.6f} --> {(auc - loss_valid):.6f}). Saving model .......!!!!\\n', log_path)\n",
    "                    torch.save(model.state_dict(), f'{cfg.out_dir}/{cfg.config}_best_f{fold_id}.pth')\n",
    "                    metric = auc - loss_valid                    \n",
    "                \n",
    "                # acc is main target (competition evaluation metric), so keeping it in both condition.\n",
    "                if (auc>best_auc and acc>best_acc) or (acc>best_acc and macro_score>best_macro):\n",
    "                    torch.save(model.state_dict(), f'{cfg.out_dir}/{cfg.config}_last_f{fold_id}.pth')\n",
    "                    best_auc=auc\n",
    "                    best_acc=acc                    \n",
    "                    best_macro=macro_score\n",
    "\n",
    "            # torch.save(model.state_dict(), f'{cfg.out_dir}/{cfg.config}_last_f{fold_id}.pth')\n",
    "\n",
    "            model = scheduler = optimizer = None\n",
    "            _ = torch.cuda.empty_cache()\n",
    "            _ = gc.collect()   \n",
    "            \n",
    "            \n",
    "        elif cfg.mode == 'val':\n",
    "            if fold_id > 4: continue\n",
    "                \n",
    "            # chpt_path = f'{cfg.out_dir}/best_metric_f{fold_id}.pth'\n",
    "            chpt_path = f'{cfg.out_dir_val}/{cfg.config}_last_f{fold_id}.pth'\n",
    "\n",
    "            print(f' load {chpt_path}!')\n",
    "            checkpoint = torch.load(chpt_path, map_location=\"cpu\")\n",
    "            model.load_state_dict(checkpoint)\n",
    "\n",
    "            train_loader, valid_loader, total_steps, val_df =  get_dataloader(fold_id)\n",
    "            loss_valid, auc, acc, macro_score, y_preds = valid_func(model, valid_loader)\n",
    "            print(f'val loss: {loss_valid:.6f}, auc: {auc:.5f}, acc {acc:.5f}, macro_score {macro_score:.5f}')\n",
    "            val_df['pred'] = y_preds\n",
    "            f_preds.append(val_df)\n",
    "\n",
    "            if int(parser_args.tta) == 1:\n",
    "                val_df.to_csv(f'{cfg.out_dir}/oof_{cfg.config}_f{fold_id}_tta.csv', index=False)\n",
    "            else:\n",
    "                val_df.to_csv(f'{cfg.out_dir}/oof_{cfg.config}_f{fold_id}.csv', index=False)\n",
    "            \n",
    "            model = checkpoint = None\n",
    "            _ = torch.cuda.empty_cache()\n",
    "            _ = gc.collect()               \n",
    "            \n",
    "    if cfg.mode == 'val':\n",
    "        oof_df = pd.concat(f_preds)\n",
    "        if int(parser_args.tta) == 1:\n",
    "            oof_df.to_csv(f'{cfg.out_dir}/oof_{cfg.config}_tta.csv', index=False)\n",
    "        else:\n",
    "            oof_df.to_csv(f'{cfg.out_dir}/oof_{cfg.config}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f2fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f05044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f745e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for kaggle notebook =>\n",
    "# cfg.load_weight = '../input/dk-1st-data-3/pretrained/vmz_ircsn_ig65m_pretrained_r50_32x2x1_58e_kinetics400_rgb_20210617-86d33018.pth'\n",
    "\n",
    "cfg.load_weight = 'pretrained/vmz_ircsn_ig65m_pretrained_r50_32x2x1_58e_kinetics400_rgb_20210617-86d33018.pth'\n",
    "# cfg.load_weight = 'kaggle/r50ir_csn_c15_m1_d2_all_last_f0.pth'\n",
    "cfg.epochs = 15\n",
    "\n",
    "\n",
    "cfg.config = 'r50ir_csn_c15_m1_d2_all' # r50ir_csn_c11_m1_d2_G_all, r50ir_csn_c15_m1_d2_G_all\n",
    "cfg.batch_size = 1\n",
    "cfg.lr = 1876e-9# 1876e-8\n",
    "cfg.device = \"cuda\"#\"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700f43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d9321ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== FOLD 4 =======\n",
      "load pretrained weight pretrained/vmz_ircsn_ig65m_pretrained_r50_32x2x1_58e_kinetics400_rgb_20210617-86d33018.pth!!!\n",
      "Transferred 318/320 items from pretrained/vmz_ircsn_ig65m_pretrained_r50_32x2x1_58e_kinetics400_rgb_20210617-86d33018.pth\n",
      "(94093, 7)\n",
      "0    18120\n",
      "1    10067\n",
      "Name: contact, dtype: int64\n",
      "Fold: 4, is_train: True, total frame 28187\n",
      "0    399\n",
      "1    356\n",
      "Name: contact, dtype: int64\n",
      "Fold: 4, is_train: False, total frame 755\n",
      "cfg.sampler =>  0\n",
      "num_steps 422805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.26396, smth: 0.42255, LR 0.000002: 100%|█| 28187/28187 [5:01:37<00:00,  \n",
      "loss: 0.46143, smth: 0.61302: 100%|███████████| 755/755 [03:13<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 1) (755,)\n",
      "[EPOCH] 1, train_loss: 0.525991,  val loss: 0.613016, auc: 0.83206, acc 0.37562, macro_score 0.57258\n",
      "[EPOCH] 1 ===============> best_metric (0.000000 --> 0.219043). Saving model .......!!!!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.25359, smth: 0.36164, LR 0.000002: 100%|█| 28187/28187 [5:00:31<00:00,  \n",
      "loss: 0.47257, smth: 0.57465: 100%|███████████| 755/755 [03:13<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 1) (755,)\n",
      "[EPOCH] 2, train_loss: 0.389769,  val loss: 0.574645, auc: 0.84833, acc 0.50777, macro_score 0.69206\n",
      "[EPOCH] 2 ===============> best_metric (0.219043 --> 0.273683). Saving model .......!!!!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.17561, smth: 0.33083, LR 0.000002: 100%|█| 28187/28187 [5:02:20<00:00,  \n",
      "loss: 0.42371, smth: 0.57699: 100%|███████████| 755/755 [03:12<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 1) (755,)\n",
      "[EPOCH] 3, train_loss: 0.342126,  val loss: 0.576994, auc: 0.83402, acc 0.56277, macro_score 0.73729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.08297, smth: 0.31721, LR 0.000001: 100%|█| 28187/28187 [5:02:42<00:00,  \n",
      "loss: 2.22864, smth: 1.12844: 100%|███████████| 755/755 [03:13<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 1) (755,)\n",
      "[EPOCH] 4, train_loss: 0.314164,  val loss: 1.128444, auc: 0.54838, acc 0.00000, macro_score 0.32043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.14170, smth: 0.28535, LR 0.000001: 100%|█| 28187/28187 [5:01:10<00:00,  \n",
      "loss: 0.59868, smth: 0.58644: 100%|███████████| 755/755 [03:12<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 1) (755,)\n",
      "[EPOCH] 5, train_loss: 0.291012,  val loss: 0.586439, auc: 0.81742, acc 0.57562, macro_score 0.75378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.74286, smth: 0.26663, LR 0.000001:   3%| | 768/28187 [08:15<4:54:45,  1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_378284/794127476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_378284/1613125626.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_accumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_accumulate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg.folds = [4]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 11 g =>\n",
    "# f2 =>\n",
    "# [EPOCH] 6, train_loss: 0.131609,  val loss: 0.440705, auc: 0.80264, acc 0.57309, macro_score 0.78258\n",
    "\n",
    "# f1 =>\n",
    "# [EPOCH] 5, train_loss: 0.127586,  val loss: 0.392070, auc: 0.90474, acc 0.69466, macro_score 0.84713\n",
    "\n",
    "\n",
    "# f0 =>\n",
    "#[EPOCH] 8, train_loss: 0.149220,  val loss: 0.317695, auc: 0.96655, acc 0.81134, macro_score 0.90563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15963c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 15 g =>\n",
    "# f2 =>\n",
    "# [EPOCH] 9, train_loss: 0.147380,  val loss: 0.379531, auc: 0.82559, acc 0.60795, macro_score 0.79601\n",
    "\n",
    "# f1 =>\n",
    "# [EPOCH] 7, train_loss: 0.172915,  val loss: 0.313531, auc: 0.89974, acc 0.74610, macro_score 0.86937\n",
    "\n",
    "# f0 =>\n",
    "# [EPOCH] 3, train_loss: 0.227716,  val loss: 0.300652, auc: 0.91696, acc 0.56272, macro_score 0.75591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bb914",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 15 =>\n",
    "# f2 =>\n",
    "# [EPOCH] 4, train_loss: 0.254828,  val loss: 0.526849, auc: 0.89088, acc 0.63712, macro_score 0.81127\n",
    "\n",
    "# f0 =>\n",
    "#[EPOCH] 4, train_loss: 0.281130,  val loss: 0.492572, auc: 0.91551, acc 0.69613, macro_score 0.84370\n",
    "\n",
    "# f3 =>\n",
    "# [EPOCH] 3, train_loss: 0.375842,  val loss: 0.561336, auc: 0.84152, acc 0.53353, macro_score 0.72987\n",
    "\n",
    "# f4 =>\n",
    "# [EPOCH] 5, train_loss: 0.291012,  val loss: 0.586439, auc: 0.81742, acc 0.57562, macro_score 0.75378"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e76168",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a44fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ec4264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " load kaggle/r50ir_csn_c15_m1_d2_all_last_f3.pth!\n",
      "(91801, 7)\n",
      "0    31840\n",
      "1    17689\n",
      "Name: contact, dtype: int64\n",
      "Fold: 3, is_train: True, total frame 49529\n",
      "Fold: 3, is_train: False, total frame 21646\n",
      "cfg.sampler =>  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.28222, smth: 0.50754: 100%|███████| 3608/3608 [1:02:42<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21646, 1) (21646,)\n",
      "val loss: 0.507535, auc: 0.80863, acc 0.51533, macro_score 0.74140\n",
      " load kaggle/r50ir_csn_c15_m1_d2_all_last_f4.pth!\n",
      "(91801, 7)\n",
      "0    32932\n",
      "1    18296\n",
      "Name: contact, dtype: int64\n",
      "Fold: 4, is_train: True, total frame 51228\n",
      "Fold: 4, is_train: False, total frame 17033\n",
      "cfg.sampler =>  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.48984, smth: 0.55941: 100%|█████████| 2839/2839 [49:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17033, 1) (17033,)\n",
      "val loss: 0.559410, auc: 0.78100, acc 0.51730, macro_score 0.74129\n"
     ]
    }
   ],
   "source": [
    "cfg.device = \"cuda\"#\"cpu\"\n",
    "cfg.config = 'r50ir_csn_c15_m1_d2_all' # r50ir_csn_c11_m1_d2_G_all\n",
    "\n",
    "cfg.batch_size = 6\n",
    "cfg.out_dir_val = 'kaggle'\n",
    "cfg.mode = 'val'\n",
    "cfg.folds = [3,4]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554ad9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b3b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
